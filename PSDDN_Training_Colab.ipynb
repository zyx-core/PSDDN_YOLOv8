{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ PSDDN Training - Optimization & Refinement Edition (V4)\n",
                "\n",
                "This version enables **Active GT Refinement** and **Counting Metrics** (MAE/MSE).\n",
                "\n",
                "**Setup**: Runtime ‚Üí Change runtime type ‚Üí **GPU (T4)**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup & Mounting Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install ultralytics scipy -q\n",
                "from google.colab import drive\n",
                "import os\n",
                "import shutil\n",
                "import json\n",
                "from pathlib import Path\n",
                "drive.mount('/content/drive')\n",
                "print('‚úÖ Drive Mounted!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Clone Repository & Inject Optimized Trainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd /content\n",
                "!rm -rf PSDDN_YOLOv8\n",
                "!git clone https://github.com/zyx-core/PSDDN_YOLOv8.git\n",
                "%cd PSDDN_YOLOv8\n",
                "!git clone https://github.com/ultralytics/ultralytics.git ultralytics_repo\n",
                "\n",
                "print(\"üíâ Injecting optimized psddn_trainer.py with Active Refinement...\")\n",
                "trainer_code = r\"\"\"import json\n",
                "from pathlib import Path\n",
                "from typing import Dict, List\n",
                "import torch\n",
                "import numpy as np\n",
                "from ultralytics.models.yolo.detect import DetectionTrainer\n",
                "try:\n",
                "    from ultralytics.utils.psddn_loss import PSDDNDetectionLoss\n",
                "except ImportError:\n",
                "    from psddn_loss import PSDDNDetectionLoss\n",
                "from ultralytics.utils import DEFAULT_CFG, LOGGER\n",
                "from online_gt_updater import OnlineGTUpdater\n",
                "\n",
                "class PSDDNTrainer(DetectionTrainer):\n",
                "    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):\n",
                "        super().__init__(cfg, overrides, _callbacks)\n",
                "        self.epoch = getattr(self, 'start_epoch', 0)\n",
                "        if overrides and 'epochs' in overrides: self.args.epochs = overrides['epochs']\n",
                "        \n",
                "        # Initialization\n",
                "        self.gt_update_interval = 10\n",
                "        self.last_gt_update_epoch = 0\n",
                "        self.curriculum_folds = []\n",
                "        self.fold_epochs = [30, 30, 40]\n",
                "        \n",
                "        # Active Refinement Setup\n",
                "        nn_file = overrides.get('nn_distances')\n",
                "        if nn_file and Path(nn_file).exists():\n",
                "            self.gt_updater = OnlineGTUpdater(\n",
                "                labels_dir=overrides.get('labels_dir', 'data/labels'),\n",
                "                initial_nn_distances_file=nn_file,\n",
                "                confidence_threshold=0.4\n",
                "            )\n",
                "            LOGGER.info(f'‚úÖ Refinement active for {nn_file}')\n",
                "        else:\n",
                "            self.gt_updater = None\n",
                "            LOGGER.warning('‚ö†Ô∏è Refinement disabled (no NN file)')\n",
                "\n",
                "    def get_loss(self, model):\n",
                "        return PSDDNDetectionLoss(model)\n",
                "\n",
                "    def load_curriculum_folds(self, folds_dir: str):\n",
                "        folds_path = Path(folds_dir)\n",
                "        for i in range(1, 4):\n",
                "            f_path = folds_path / f'fold_{i}.json'\n",
                "            if f_path.exists():\n",
                "                with open(f_path, 'r') as f: data = json.load(f)\n",
                "                stems = [Path(x).stem.replace('processed_', '') for x in data]\n",
                "                self.curriculum_folds.append(stems)\n",
                "                LOGGER.info(f'Fold {i}: {len(stems)} keys')\n",
                "            else: self.curriculum_folds.append([])\n",
                "\n",
                "    def get_active_images(self) -> List[str]:\n",
                "        cum = 0; stage = 1; ep = getattr(self, 'epoch', 0)\n",
                "        for i, eps in enumerate(self.fold_epochs, 1): \n",
                "            cum += eps\n",
                "            if ep < cum: stage = i; break\n",
                "        active = []\n",
                "        for i in range(stage): \n",
                "            if i < len(self.curriculum_folds): active.extend(self.curriculum_folds[i])\n",
                "        return active\n",
                "\n",
                "    def _do_train(self, world_size=1):\n",
                "        self.add_callback('on_train_epoch_end', self.on_epoch_end_callback)\n",
                "        super()._do_train()\n",
                "\n",
                "    def on_epoch_end_callback(self, trainer):\n",
                "        if (self.epoch - self.last_gt_update_epoch) >= self.gt_update_interval:\n",
                "            self.last_gt_update_epoch = self.epoch\n",
                "            self.update_pseudo_gt()\n",
                "\n",
                "    def update_pseudo_gt(self):\n",
                "        if not self.gt_updater: return\n",
                "        LOGGER.info(f'üõ†Ô∏è Epoch {self.epoch}: Tightening boxes...')\n",
                "        stems = self.get_active_images()\n",
                "        paths = [x for x in self.train_loader.dataset.im_files if Path(x).stem.replace('processed_', '') in stems]\n",
                "        stats = self.gt_updater.update_gt(model=self.model, image_paths=paths, device=next(self.model.parameters()).device)\n",
                "        LOGGER.info(f'‚úÖ Refined {stats[\"updated_boxes\"]} / {stats[\"total_boxes\"]} boxes')\n",
                "\n",
                "    def build_dataset(self, img_path, mode='train', batch=None):\n",
                "        from ultralytics.data.dataset import YOLODataset\n",
                "        ds = YOLODataset(img_path=img_path, imgsz=self.args.imgsz, batch_size=batch, augment=mode=='train', hyp=self.args, rect=self.args.rect, cache=self.args.cache or None, single_cls=self.args.single_cls, stride=int(self.stride), pad=0.0, data=self.data, classes=self.args.classes, task=self.args.task)\n",
                "        if mode == 'train' and self.curriculum_folds:\n",
                "            stems = self.get_active_images()\n",
                "            f_im, f_lb = [], []\n",
                "            for im, lb in zip(ds.im_files, ds.labels):\n",
                "                if Path(im).stem.replace('processed_', '') in stems: f_im.append(im); f_lb.append(lb)\n",
                "            if f_im: ds.im_files, ds.labels = f_im, f_lb\n",
                "            LOGGER.info(f'Curriculum: {len(ds.im_files)} active images')\n",
                "        return ds\n",
                "\n",
                "def train_psddn(data_yaml, folds_dir, nn_distances, labels_dir, **kwargs):\n",
                "    trainer = PSDDNTrainer(overrides={'data': data_yaml, 'nn_distances': nn_distances, 'labels_dir': labels_dir, **kwargs})\n",
                "    trainer.load_curriculum_folds(folds_dir)\n",
                "    trainer.train()\n",
                "    return trainer\n",
                "\"\"\"\n",
                "with open('scripts/psddn_trainer.py', 'w') as f: f.write(trainer_code)\n",
                "print('‚úÖ Optimized Trainer Injected!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Link Data & Generate Refinement Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "drive_paths = glob.glob('/content/drive/MyDrive/**/part_B/train_data/images', recursive=True)\n",
                "if drive_paths:\n",
                "    DATA_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(drive_paths[0]))))\n",
                "    os.symlink(DATA_ROOT, 'data')\n",
                "    print(f'‚úÖ Link created: data -> {DATA_ROOT}')\n",
                "    \n",
                "    # Generate NN distances for Refinement\n",
                "    print(\"üìä Generating initial NN distances for refinement...\")\n",
                "    LABELS_DIR = '/content/PSDDN_YOLOv8/data/ShanghaiTech/part_B/train_data/labels'\n",
                "    FOLDS_DIR = '/content/PSDDN_YOLOv8/data/ShanghaiTech/folds'\n",
                "    NN_FILE = os.path.join(FOLDS_DIR, 'initial_nn_distances.json')\n",
                "    \n",
                "    import sys\n",
                "    sys.path.append('scripts')\n",
                "    from online_gt_updater import create_nn_distances_file\n",
                "    # Use the JSON conversion if MAT isn't available\n",
                "    MAT_FILE = '/content/PSDDN_YOLOv8/data/ShanghaiTech/part_B_train.json'\n",
                "    create_nn_distances_file(MAT_FILE, NN_FILE, format='json')\n",
                "    print(f\"‚úÖ NN distances saved to {NN_FILE}\")\n",
                "else:\n",
                "    print(\"‚ùå ERROR: Data not found!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ 4Ô∏è‚É£ Run Training with Active Refinement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/PSDDN_YOLOv8/ultralytics_repo')\n",
                "sys.path.insert(0, '/content/PSDDN_YOLOv8/scripts')\n",
                "from psddn_trainer import train_psddn\n",
                "\n",
                "train_psddn(\n",
                "    data_yaml='data/ShanghaiTech/shanghaitech_partB.yaml',\n",
                "    folds_dir='data/ShanghaiTech/folds',\n",
                "    nn_distances='data/ShanghaiTech/folds/initial_nn_distances.json',\n",
                "    labels_dir='/content/PSDDN_YOLOv8/data/ShanghaiTech/part_B/train_data/labels',\n",
                "    model='yolov8n.pt',\n",
                "    epochs=50, # Set to 100 for full run\n",
                "    batch=16,\n",
                "    name='optimized_psddn'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä 5Ô∏è‚É£ Analysis: Counting Accuracy (MAE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python scripts/analyze_counting.py \\\n",
                "    --model runs/psddn/optimized_psddn/weights/best.pt \\\n",
                "    --images data/ShanghaiTech/part_B/test_data/images \\\n",
                "    --gt data/ShanghaiTech/part_B_test.json \\\n",
                "    --output runs/psddn/final_analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Results Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!zip -r refined_results.zip runs/psddn\n",
                "from google.colab import files\n",
                "files.download('refined_results.zip')"
            ]
        }
    ],\
    "metadata": {\
        "accelerator": "GPU",\
        "colab": {\
            "gpuType": "T4"\
        },\
        "kernelspec": {\
            "display_name": "Python 3",\
            "name": "python3"\
        }\
    },\
    "nbformat": 4,\
    "nbformat_minor": 0\
}